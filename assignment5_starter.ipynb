{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the KNN class\n",
    "class KNN:\n",
    "    def __init__(self, k=3, distance_metric='euclidean'):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = []\n",
    "        for x_test in X:\n",
    "            distances = self.compute_distance(self.X_train, x_test)\n",
    "            k_indices = distances.argsort()[:self.k]\n",
    "            k_nearest_labels = self.y_train[k_indices]\n",
    "            prob = np.mean(k_nearest_labels)\n",
    "            y_pred.append(prob)\n",
    "        return np.array(y_pred)\n",
    "    \n",
    "\n",
    "    def compute_distance(self, X_train, x_test):\n",
    "        if self.distance_metric == 'euclidean':\n",
    "            distances = np.sqrt(np.sum((X_train - x_test) ** 2, axis=1))\n",
    "        elif self.distance_metric == 'manhattan':\n",
    "            distances = np.sum(np.abs(X_train - x_test), axis=1)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported distance metric\")\n",
    "        return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data preprocessing function\n",
    "def preprocess_data(train_path, test_path):\n",
    "    train_data = pd.read_csv(train_path)\n",
    "    test_data = pd.read_csv(test_path)\n",
    "\n",
    "    # Handle missing values (if any)\n",
    "    # For this dataset, we'll check for missing values\n",
    "    if train_data.isnull().sum().any() or test_data.isnull().sum().any():\n",
    "        # Implement missing value handling if needed\n",
    "        train_data.fillna(train_data.mean(), inplace=True)\n",
    "        test_data.fillna(test_data.mean(), inplace=True)\n",
    "\n",
    "    # Save 'id' from test_data for submission\n",
    "    test_ids = test_data['id'].values\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    # For training data, drop 'id', 'CustomerId', 'Surname'\n",
    "    train_data.drop(['id', 'CustomerId', 'Surname'], axis=1, inplace=True)\n",
    "    # For test data, drop 'CustomerId', 'Surname' (keep 'id' for submission)\n",
    "    test_data.drop(['CustomerId', 'Surname'], axis=1, inplace=True)\n",
    "\n",
    "    # Encode categorical variables\n",
    "    # Label Encoding for Gender\n",
    "    le = LabelEncoder()\n",
    "    train_data['Gender'] = le.fit_transform(train_data['Gender'])\n",
    "    test_data['Gender'] = le.transform(test_data['Gender'])\n",
    "\n",
    "    # One-Hot Encoding for Geography\n",
    "    train_data = pd.get_dummies(train_data, columns=['Geography'], drop_first=True)\n",
    "    test_data = pd.get_dummies(test_data, columns=['Geography'], drop_first=True)\n",
    "\n",
    "    # Ensure both datasets have the same dummy variables\n",
    "    missing_cols = set(train_data.columns) - set(test_data.columns)\n",
    "    for c in missing_cols:\n",
    "        test_data[c] = 0\n",
    "    test_data = test_data[train_data.columns.drop('Exited')]\n",
    "\n",
    "    # Separate features and target variable\n",
    "    X = train_data.drop('Exited', axis=1).values\n",
    "    y = train_data['Exited'].values\n",
    "    X_test = test_data.values\n",
    "\n",
    "    # Feature Scaling\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    return X, y, X_test, test_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cross-validation function\n",
    "def cross_validate(X, y, k, distance_metric, n_splits=5):\n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "    roc_auc_scores = []\n",
    "\n",
    "    for train_index, val_index in skf.split(X, y):\n",
    "        X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "        y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "\n",
    "        knn = KNN(k=k, distance_metric=distance_metric)\n",
    "        knn.fit(X_train_fold, y_train_fold)\n",
    "        y_val_pred = knn.predict(X_val_fold)\n",
    "        score = roc_auc_score(y_val_fold, y_val_pred)\n",
    "        roc_auc_scores.append(score)\n",
    "\n",
    "    return np.mean(roc_auc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1, metric=euclidean, ROC AUC=0.7532\n",
      "k=2, metric=euclidean, ROC AUC=0.8153\n",
      "k=3, metric=euclidean, ROC AUC=0.8446\n",
      "k=4, metric=euclidean, ROC AUC=0.8618\n",
      "k=5, metric=euclidean, ROC AUC=0.8717\n",
      "k=6, metric=euclidean, ROC AUC=0.8771\n",
      "k=7, metric=euclidean, ROC AUC=0.8815\n",
      "k=8, metric=euclidean, ROC AUC=0.8855\n",
      "k=9, metric=euclidean, ROC AUC=0.8872\n",
      "k=10, metric=euclidean, ROC AUC=0.8905\n",
      "k=11, metric=euclidean, ROC AUC=0.8920\n",
      "k=12, metric=euclidean, ROC AUC=0.8948\n",
      "k=13, metric=euclidean, ROC AUC=0.8968\n",
      "k=14, metric=euclidean, ROC AUC=0.8970\n",
      "k=15, metric=euclidean, ROC AUC=0.8969\n",
      "k=16, metric=euclidean, ROC AUC=0.8981\n",
      "k=17, metric=euclidean, ROC AUC=0.8984\n",
      "k=18, metric=euclidean, ROC AUC=0.8994\n",
      "k=19, metric=euclidean, ROC AUC=0.9006\n",
      "k=20, metric=euclidean, ROC AUC=0.9007\n",
      "k=1, metric=manhattan, ROC AUC=0.7508\n",
      "k=2, metric=manhattan, ROC AUC=0.8172\n",
      "k=3, metric=manhattan, ROC AUC=0.8471\n",
      "k=4, metric=manhattan, ROC AUC=0.8636\n",
      "k=5, metric=manhattan, ROC AUC=0.8736\n",
      "k=6, metric=manhattan, ROC AUC=0.8789\n",
      "k=7, metric=manhattan, ROC AUC=0.8834\n",
      "k=8, metric=manhattan, ROC AUC=0.8884\n",
      "k=9, metric=manhattan, ROC AUC=0.8905\n",
      "k=10, metric=manhattan, ROC AUC=0.8932\n",
      "k=11, metric=manhattan, ROC AUC=0.8949\n",
      "k=12, metric=manhattan, ROC AUC=0.8958\n",
      "k=13, metric=manhattan, ROC AUC=0.8970\n",
      "k=14, metric=manhattan, ROC AUC=0.8978\n",
      "k=15, metric=manhattan, ROC AUC=0.8995\n",
      "k=16, metric=manhattan, ROC AUC=0.9009\n",
      "k=17, metric=manhattan, ROC AUC=0.9014\n",
      "k=18, metric=manhattan, ROC AUC=0.9020\n",
      "k=19, metric=manhattan, ROC AUC=0.9022\n",
      "k=20, metric=manhattan, ROC AUC=0.9028\n",
      "\n",
      "Best ROC AUC Score: 0.9028\n",
      "Optimal k: 20\n",
      "Optimal Distance Metric: manhattan\n",
      "Submission file 'submissions.csv' has been created.\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "X, y, X_test, test_ids = preprocess_data('train.csv', 'test.csv')\n",
    "\n",
    "# Hyperparameter tuning\n",
    "best_score = 0\n",
    "best_k = None\n",
    "best_metric = None\n",
    "\n",
    "for metric in ['euclidean', 'manhattan']:\n",
    "    for k in range(1, 21):\n",
    "        score = cross_validate(X, y, k, metric, n_splits=5)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_k = k\n",
    "            best_metric = metric\n",
    "        print(f\"k={k}, metric={metric}, ROC AUC={score:.4f}\")\n",
    "\n",
    "print(f\"\\nBest ROC AUC Score: {best_score:.4f}\")\n",
    "print(f\"Optimal k: {best_k}\")\n",
    "print(f\"Optimal Distance Metric: {best_metric}\")\n",
    "\n",
    "# Train on full dataset with optimal hyperparameters and make predictions on test set\n",
    "knn = KNN(k=best_k, distance_metric=best_metric)\n",
    "knn.fit(X, y)\n",
    "test_predictions = knn.predict(X_test)\n",
    "\n",
    "# Ensure predictions are between 0 and 1\n",
    "test_predictions = np.clip(test_predictions, 0, 1)\n",
    "\n",
    "# Save test predictions\n",
    "submission = pd.DataFrame({'id': test_ids, 'Exited': test_predictions})\n",
    "submission.to_csv('submissions.csv', index=False)\n",
    "\n",
    "\n",
    "print(\"Submission file 'submissions.csv' has been created.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
